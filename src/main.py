import sys
from typing import Callable, List, NoReturn

import numpy as np
from dotenv import load_dotenv
from tqdm import tqdm

from classes.VectorStoreFRIDA import VectorStoreFRIDA
from others.frida import get_frida_embeddings
from others.wiki_scraper import process_text_file


def main() -> NoReturn:
    load_dotenv()
    try:
        add_to_vector_store = True
        source_text = "llm.txt"
        CHUNK_SIZE = 1000
        BATCH_SIZE = 20

        if add_to_vector_store:
            # –ß—Ç–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏
            chunked_text: List[str] = process_text_file(source_text, CHUNK_SIZE)
            total_chunks = len(chunked_text)
            total_batches = (total_chunks - 1) // BATCH_SIZE + 1

            print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            print(f"  ‚Ä¢ –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {total_chunks}")
            print(f"  ‚Ä¢ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {BATCH_SIZE}")
            print(f"  ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π: {total_batches}\n")

            vector_store = VectorStoreFRIDA()
            embedding_function: Callable[[List[str]], np.ndarray] = get_frida_embeddings

            total_added = 0
            total_skipped = 0

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞–º–∏
            print("‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ:\n")
            for batch_index, batch_start in enumerate(
                tqdm(range(0, total_chunks, BATCH_SIZE), total=total_batches, desc="–ë–∞—Ç—á–∏", ncols=100, unit="batch")
            ):
                batch_end = min(batch_start + BATCH_SIZE, total_chunks)
                batch_chunks = chunked_text[batch_start:batch_end]

                # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –±–∞—Ç—á–∞
                batch_embeddings: np.ndarray = embedding_function(batch_chunks, device="cpu")

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –±–∞—Ç—á–∞
                batch_metadatas = [
                    {
                        "source": "simple_scraper",
                        "url": source_text,
                        "chunk_index": batch_start + i,
                        "total_chunks": total_chunks,
                        "batch_index": batch_index,
                    }
                    for i in range(len(batch_chunks))
                ]

                # –î–æ–±–∞–≤–ª—è–µ–º –±–∞—Ç—á –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è
                added, skipped = vector_store.add_chunks_batch(
                    chunks=batch_chunks,
                    embeddings=batch_embeddings,
                    metadatas=batch_metadatas,
                )

                total_added += added
                total_skipped += skipped

                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–±–∞—Ä–∞
                tqdm.write(
                    f"  üì¶ –ë–∞—Ç—á {batch_index + 1}/{total_batches}: "
                    f"–¥–æ–±–∞–≤–ª–µ–Ω–æ {added}, –ø—Ä–æ–ø—É—â–µ–Ω–æ {skipped}"
                )

            print("\n‚úÖ –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω:")
            print(f"  ‚Ä¢ –î–æ–±–∞–≤–ª–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {total_added}")
            print(f"  ‚Ä¢ –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç): {total_skipped}")
            print(f"  ‚Ä¢ –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_added + total_skipped}")
            print("üéâ –í—Å–µ —á–∞–Ω–∫–∏ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ!")

    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞:", e, file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
