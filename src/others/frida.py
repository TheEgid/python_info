import logging
import shutil
import tempfile
import time
from pathlib import Path
from typing import List

import numpy as np
import requests
from sentence_transformers import SentenceTransformer

logger = logging.getLogger(__name__)


def save_model_locally(
    model_name: str = "ai-forever/FRIDA",
    local_model_dir: str = "./local_llm_models",
    max_retries: int = 3,
    retry_delay: float = 5.0,
    verify_integrity: bool = True,
    show_progress: bool = True,
) -> str:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –ª–æ–∫–∞–ª—å–Ω–æ —Å –Ω–∞–¥–µ–∂–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π –∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏.

    Args:
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ SentenceTransformer
        local_model_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
        retry_delay: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        verify_integrity: –ü—Ä–æ–≤–µ—Ä—è—Ç—å —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
        show_progress: –í—ã–≤–æ–¥–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –ª–æ–≥

    Returns:
        –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    """
    local_model_path = Path(local_model_dir) / model_name.replace("/", "_")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ –≤ –∫–µ—à–µ
    if local_model_path.exists() and _is_model_valid(local_model_path):
        size_mb = _get_dir_size(local_model_path) / (1024**2)
        logger.info(f"‚úì –ú–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞ –≤ –∫–µ—à–µ: {local_model_path} ({size_mb:.2f} MB)")
        return str(local_model_path)

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    local_model_path.parent.mkdir(parents=True, exist_ok=True)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ
    _check_disk_space(local_model_path.parent)

    current_retry_delay = retry_delay

    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
    for attempt in range(max_retries):
        temp_model_path = None
        try:
            logger.info(f"\n{'‚îÄ' * 70}")
            logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}: –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ '{model_name}'")
            logger.info(f"{'‚îÄ' * 70}")

            with tempfile.TemporaryDirectory(prefix="model_temp_") as temp_dir:
                temp_model_path = Path(temp_dir) / "model"
                temp_model_path.mkdir(parents=True, exist_ok=True)

                if show_progress:
                    logger.info("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")

                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
                model = _load_model_with_progress(model_name, attempt)

                if show_progress:
                    logger.info("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

                model.save(str(temp_model_path))

                if show_progress:
                    logger.info("üì¶ –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –≤ —Ñ–∏–Ω–∞–ª—å–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é...")

                if local_model_path.exists():
                    shutil.rmtree(local_model_path, ignore_errors=True)

                shutil.move(str(temp_model_path), str(local_model_path))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            if not local_model_path.exists() or not list(local_model_path.glob("*")):
                raise IOError(f"–ú–æ–¥–µ–ª—å –Ω–µ –±—ã–ª–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {local_model_path}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å
            if verify_integrity:
                _verify_model_integrity(local_model_path, model_name)

            size_mb = _get_dir_size(local_model_path) / (1024**2)
            file_count = len(list(local_model_path.rglob("*")))
            logger.info(f"\n{'‚úì' * 35}")
            logger.info("‚úì –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
            logger.info(f"  –ü—É—Ç—å: {local_model_path}")
            logger.info(f"  –†–∞–∑–º–µ—Ä: {size_mb:.2f} MB")
            logger.info(f"  –§–∞–π–ª–æ–≤: {file_count}")
            logger.info(f"{'‚úì' * 35}\n")

            return str(local_model_path)

        except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:
            error_type = type(e).__name__
            logger.warning(f"‚ö† {error_type} –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}: {e}")
            _handle_retry_attempt(attempt, max_retries, current_retry_delay)
            current_retry_delay *= 2

        except requests.exceptions.RequestException as e:
            logger.warning(f"üåê –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}: {e}")
            _handle_retry_attempt(attempt, max_retries, current_retry_delay)
            current_retry_delay *= 2

        except IOError as e:
            logger.error(f"üíæ –û—à–∏–±–∫–∞ –≤–≤–æ–¥–∞/–≤—ã–≤–æ–¥–∞: {e}")
            if attempt < max_retries - 1:
                logger.info(f"‚è≥ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {current_retry_delay:.1f} —Å–µ–∫...")
                time.sleep(current_retry_delay)
                current_retry_delay *= 2
            else:
                logger.error(f"‚úó –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫")
                raise

        except Exception as e:
            logger.error(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {type(e).__name__}: {str(e)[:200]}")
            _handle_retry_attempt(attempt, max_retries, current_retry_delay)
            current_retry_delay *= 2

        finally:
            if temp_model_path and Path(temp_model_path).exists():
                try:
                    shutil.rmtree(temp_model_path, ignore_errors=True)
                except Exception as cleanup_error:
                    logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {cleanup_error}")

    raise Exception(f"‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å '{model_name}' –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫")


def _load_model_with_progress(model_name: str, attempt: int) -> SentenceTransformer:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º —ç—Ç–∞–ø–æ–≤."""
    stages = [
        "–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é...",
        "–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...",
        "–ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏...",
        "–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞...",
        "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...",
    ]

    for i, stage in enumerate(stages, 1):
        logger.info(f"  [{i}/{len(stages)}] {stage}")

    try:
        model = SentenceTransformer(model_name, device="cpu")
        logger.info("  ‚úì –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤ –ø–∞–º—è—Ç–∏")
        return model
    except Exception as e:
        logger.error(f"  ‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {type(e).__name__}: {e}")
        raise


def _handle_retry_attempt(attempt: int, max_retries: int, delay: float) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏."""
    if attempt < max_retries - 1:
        logger.info(f"‚è≥ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {delay:.1f} —Å–µ–∫—É–Ω–¥...")
        time.sleep(delay)
    else:
        logger.error(f"‚úó –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –ø–æ–ø—ã—Ç–æ–∫ ({max_retries})")


def _verify_model_integrity(model_path: Path, model_name: str) -> None:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–∏."""
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏...")

    required_files = [
        "config.json",
        "sentence_bert_config.json",
        "pytorch_model.bin",
    ]

    found_files = 0
    for file in required_files:
        file_path = model_path / file
        if file_path.exists():
            size_mb = file_path.stat().st_size / (1024**2)
            logger.info(f"  ‚úì {file} ({size_mb:.2f} MB)")
            found_files += 1
        else:
            logger.debug(f"  - {file} (–Ω–µ –Ω–∞–π–¥–µ–Ω)")

    if found_files >= 2:
        logger.info("‚úì –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞")
    else:
        logger.warning(f"‚ö† –ù–∞–π–¥–µ–Ω–æ —Ç–æ–ª—å–∫–æ {found_files} –∏–∑ {len(required_files)} —Ñ–∞–π–ª–æ–≤")


def _is_model_valid(model_path: Path) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏."""
    try:
        required = ["config.json", "sentence_bert_config.json"]
        return all((model_path / f).exists() for f in required)
    except Exception:
        return False


def _check_disk_space(path: Path, min_space_gb: float = 2.0) -> None:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ–µ –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ."""
    try:
        stat = shutil.disk_usage(path)
        free_gb = stat.free / (1024**3)
        total_gb = stat.total / (1024**3)

        logger.info(f"üíæ –ú–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ: {free_gb:.2f} GB —Å–≤–æ–±–æ–¥–Ω–æ –∏–∑ {total_gb:.2f} GB")

        if free_gb < min_space_gb:
            logger.warning(f"‚ö† –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–µ—Å—Ç–∞! –¢—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º {min_space_gb} GB")
    except Exception as e:
        logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ: {e}")


def _get_dir_size(path: Path) -> int:
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞–∑–º–µ—Ä –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ –±–∞–π—Ç–∞—Ö."""
    total = 0
    try:
        for entry in path.rglob("*"):
            if entry.is_file():
                total += entry.stat().st_size
    except Exception:
        pass
    return total


def get_frida_embeddings(
    sentences: List[str],
    model_name: str = "ai-forever/FRIDA",
    batch_size: int = 32,
    local_model_dir: str = "./local_llm_models",
    force_redownload: bool = False,
    device: str = "cpu",
) -> np.ndarray:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ FRIDA (1536 dimensions).

    Args:
        sentences: –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        local_model_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
        force_redownload: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
        device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è ("cpu" –∏–ª–∏ "cuda")

    Returns:
        np.ndarray: –ú–∞—Å—Å–∏–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ shape=(len(sentences), 1536), dtype=float32

    Raises:
        ValueError: –ï—Å–ª–∏ sentences –ø—É—Å—Ç–æ
    """
    if not sentences:
        raise ValueError("–°–ø–∏—Å–æ–∫ sentences –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")

    logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π...")

    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        if local_model_dir:
            model_path = _get_or_download_model(
                model_name=model_name,
                local_model_dir=local_model_dir,
                force_redownload=force_redownload,
            )
        else:
            model_path = model_name
            logger.info(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å '{model_name}' –±–µ–∑ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è...")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        model = SentenceTransformer(model_path, device=device)
        logger.info(f"‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device})")

        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        logger.info(f"üîÑ –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ {len(sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–±–∞—Ç—á: {batch_size})...")
        embeddings = model.encode(
            sentences,
            batch_size=batch_size,
            show_progress_bar=True,
            convert_to_numpy=True,
        )

        if embeddings.size == 0:
            raise ValueError("–ü–æ–ª—É—á–µ–Ω—ã –ø—É—Å—Ç—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏")

        logger.info(f"‚úì –ü–æ–ª—É—á–µ–Ω—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: shape={embeddings.shape}, dtype={embeddings.dtype}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
        if embeddings.shape[1] != 1536:
            logger.warning(f"‚ö† –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {embeddings.shape[1]} (–æ–∂–∏–¥–∞–µ—Ç—Å—è 1536)")

        return embeddings

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {type(e).__name__}: {e}")
        raise


def _get_or_download_model(
    model_name: str,
    local_model_dir: str,
    force_redownload: bool = False,
) -> str:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –ª–æ–∫–∞–ª—å–Ω–æ.

    Args:
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        local_model_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        force_redownload: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞

    Returns:
        –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
    """
    local_model_path = Path(local_model_dir) / model_name.replace("/", "_")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
    if local_model_path.exists() and _is_model_valid(local_model_path) and not force_redownload:
        size_mb = _get_dir_size(local_model_path) / (1024**2)
        logger.info(f"‚úì –ú–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞ –≤ –∫–µ—à–µ ({size_mb:.2f} MB)")
        return str(local_model_path)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å
    logger.info(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å '{model_name}' –∏–∑ Hub...")
    return save_model_locally(
        model_name=model_name,
        local_model_dir=local_model_dir,
        verify_integrity=True,
        show_progress=True,
    )
