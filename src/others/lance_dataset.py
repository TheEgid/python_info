import json
import logging
from pathlib import Path
from typing import List, Optional, Tuple

import lancedb
import numpy as np
from llama_index.core import Settings, SimpleDirectoryReader
from llama_index.core.schema import Document, TextNode

from classes.PatchedLanceDBVectorStore import PatchedLanceDBVectorStore
from others.frida import FridaEmbedding

LANCE_DB_PATH = Path("./lancedb/articles_index").resolve()


def fill_lance_dataset(
    documents: List[Document],
    db_path: Path = LANCE_DB_PATH,
) -> Tuple[Optional[PatchedLanceDBVectorStore], List[TextNode]]:
    if not documents:
        logging.warning("‚ö†Ô∏è –ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.")
        return None, []

    logging.info(f"–°–æ–∑–¥–∞—ë–º LanceDB –ø–æ –ø—É—Ç–∏: {db_path}")
    db = lancedb.connect(db_path)
    table_name = "articles"

    if table_name in db.table_names():
        db.drop_table(table_name)

    embed_model = FridaEmbedding()
    Settings.embed_model = embed_model

    table_data = []
    nodes: List[TextNode] = []

    for i, doc in enumerate(documents):
        text = (doc.text or "").strip()
        if not text:
            continue

        embedding = embed_model._get_text_embedding(text)
        embedding_array = np.array(embedding, dtype=np.float32)

        doc_id = doc.doc_id or f"doc_{i}"
        metadata = {
            "doc_id": doc_id,
            "source": getattr(doc, "extra_info", {}).get("file_path", "unknown"),
        }

        table_data.append(
            {
                "id": doc_id,
                "text": text,
                "embedding": embedding_array.tolist(),
                "metadata": json.dumps(metadata),
            }
        )

        nodes.append(TextNode(text=text, embedding=embedding_array.tolist(), metadata=metadata, id_=doc_id))

    if not table_data:
        logging.warning("‚ö†Ô∏è –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.")
        return None, []

    table = db.create_table(table_name, data=table_data, mode="overwrite")

    vector_store = PatchedLanceDBVectorStore(table=table)
    logging.info(f"‚úÖ LanceDB —Å–æ–∑–¥–∞–Ω: {len(table_data)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

    return vector_store, nodes


def load_or_fill_lance(
    db_path: Path = LANCE_DB_PATH,
) -> Tuple[Optional[PatchedLanceDBVectorStore], Optional[List[TextNode]]]:
    try:
        db = lancedb.connect(db_path)
        table_name = "articles"

        if table_name in db.table_names():
            logging.info(f"üì¶ LanceDB '{table_name}' –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ...")
            table = db.open_table(table_name)
            df = table.to_pandas()  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            if df.empty:
                logging.warning(f"‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ '{table_name}' —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω–æ –ø—É—Å—Ç–∞. –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º...")
                db.drop_table(table_name)  # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—É—é –∏ –ø–µ—Ä–µ–π–¥—ë–º –∫ —Å–æ–∑–¥–∞–Ω–∏—é
            else:
                vector_store = PatchedLanceDBVectorStore(table=table)
                nodes: List[TextNode] = []
                for r in df.to_dict(orient="records"):
                    meta = r.get("metadata", {})
                    if isinstance(meta, str):
                        try:
                            meta = json.loads(meta)
                        except Exception:
                            meta = {"__node_content__": meta}
                    text = meta.get("__node_content__", r.get("text", ""))
                    nodes.append(
                        TextNode(text=text, metadata=meta, embedding=r.get("embedding"), id_=meta.get("doc_id"))
                    )
                return vector_store, nodes
        # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–∞ –∏–ª–∏ –±—ã–ª–∞ —Å–±—Ä–æ—à–µ–Ω–∞, —Å–æ–∑–¥–∞—ë–º –∑–∞–Ω–æ–≤–æ
        logging.info("üÜï LanceDB –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞—ë–º –∑–∞–Ω–æ–≤–æ...")
        articles_dir = Path("articles/")
        if not articles_dir.exists():
            logging.error(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {articles_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
            return None, None

        documents = SimpleDirectoryReader(str(articles_dir)).load_data()
        if not documents:
            logging.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏!")
            return None, None

        vector_store, nodes = fill_lance_dataset(documents, db_path=db_path)
        return vector_store, nodes

    except Exception as e:
        logging.exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å LanceDB: {e}")
        return None, None
