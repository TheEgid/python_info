import sys
from typing import Callable, List, Tuple

import numpy as np
from tqdm import tqdm

from classes.VectorStoreFRIDA import VectorStoreFRIDA
from others.frida import get_frida_embeddings
from others.wiki_scraper import process_text_file


def process_and_add_chunks(
    source_text: str,
    chunk_size: int,
    batch_size: int,
    embedding_function: Callable[[List[str]], np.ndarray],
    vector_store: VectorStoreFRIDA,
) -> Tuple[int, int]:
    """–ß–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç, —Ä–∞–∑–±–∏–≤–∞–µ—Ç –Ω–∞ —á–∞–Ω–∫–∏, –ø–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ."""
    chunked_text: List[str] = process_text_file(source_text, chunk_size)
    total_chunks = len(chunked_text)
    total_batches = (total_chunks - 1) // batch_size + 1

    print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  ‚Ä¢ –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {total_chunks}")
    print(f"  ‚Ä¢ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_size}")
    print(f"  ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π: {total_batches}\n")

    total_added = 0
    total_skipped = 0

    print("‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ:\n")

    for batch_index, batch_start in enumerate(
        tqdm(range(0, total_chunks, batch_size), total=total_batches, desc="–ë–∞—Ç—á–∏", ncols=100, unit="batch")
    ):
        batch_end = min(batch_start + batch_size, total_chunks)
        batch_chunks = chunked_text[batch_start:batch_end]

        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –±–∞—Ç—á–∞
        batch_embeddings: np.ndarray = embedding_function(batch_chunks, device="cpu")

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        batch_metadatas = [
            {
                "source": "simple_scraper",
                "url": source_text,
                "chunk_index": batch_start + i,
                "total_chunks": total_chunks,
                "batch_index": batch_index,
            }
            for i in range(len(batch_chunks))
        ]

        added, skipped = vector_store.add_chunks_batch(
            chunks=batch_chunks,
            embeddings=batch_embeddings,
            metadatas=batch_metadatas,
        )

        total_added += added
        total_skipped += skipped

        tqdm.write(f"  üì¶ –ë–∞—Ç—á {batch_index + 1}/{total_batches}: –¥–æ–±–∞–≤–ª–µ–Ω–æ {added}, –ø—Ä–æ–ø—É—â–µ–Ω–æ {skipped}")

    return total_added, total_skipped


def run_pipeline() -> None:
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —á–∞–Ω–∫–æ–≤."""
    try:
        add_to_vector_store = True
        source_text = "llm.txt"
        CHUNK_SIZE = 1000
        BATCH_SIZE = 20

        if not add_to_vector_store:
            print("‚ÑπÔ∏è –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ.")
            return

        vector_store = VectorStoreFRIDA()
        embedding_function: Callable[[List[str]], np.ndarray] = get_frida_embeddings

        total_added, total_skipped = process_and_add_chunks(
            source_text=source_text,
            chunk_size=CHUNK_SIZE,
            batch_size=BATCH_SIZE,
            embedding_function=embedding_function,
            vector_store=vector_store,
        )

        print("\n‚úÖ –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω:")
        print(f"  ‚Ä¢ –î–æ–±–∞–≤–ª–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {total_added}")
        print(f"  ‚Ä¢ –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç): {total_skipped}")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_added + total_skipped}")
        print("üéâ –í—Å–µ —á–∞–Ω–∫–∏ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ!")

    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞:", e, file=sys.stderr)
        sys.exit(1)
